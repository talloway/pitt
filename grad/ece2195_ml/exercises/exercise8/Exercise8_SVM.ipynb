{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: SVM \n",
    "\n",
    "### Part 1:\n",
    "In this part, we will apply SVM for classification of breast cancer using the Wisconsin's data. Read the description of the dataset, then answer the following questions. Whenever needed to split the data, use random_state=0 in train_test_split\n",
    "\n",
    "#### 1) Find the accuracy of SVM classifier with parameter C=0.1, and  radial basis function kernel (rbf) of parameter Gamma =0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6294.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "CancerDataset=load_breast_cancer()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(CancerDataset['data'], CancerDataset['target'], random_state=0)\n",
    "\n",
    "svmModel = SVC(kernel='rbf', gamma=0.2, C=0.1)\n",
    "svmModel.fit(X_train, Y_train)\n",
    "\n",
    "acc = svmModel.score(X_test, Y_test)\n",
    "print('Accuracy is %.4f.' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Repeat part (1) but scale the features with MinMaxScaler. Compare results of (1) and (2) and comment on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9510.\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_t = scaler.transform(X_train)\n",
    "X_test_t = scaler.transform(X_test)\n",
    "\n",
    "svmModel.fit(X_train_t, Y_train)\n",
    "\n",
    "acc = svmModel.score(X_test_t, Y_test)\n",
    "print('Accuracy is %.4f.' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(AP)**: The accuracy is much better when using the MinMaxScaler instead of the normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Using scaled features, find best SVM classifier. Try values of the regularization C=[0.1, 1, 5] and RBF parameter Gamma = [ 0.1, 1, 5]. Use 5-fold cross validation to find the best parameters (using all possible combinations of these values for C and gamma). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best tuning parameters are c=1 and gamma=1.\n",
      "Trainval accuracy with these tuning parameters = 0.9812.\n",
      "Test accuracy with these tuning parameters = 0.9720\n"
     ]
    }
   ],
   "source": [
    "X_trainval_t = X_train_t\n",
    "Y_trainval = Y_train\n",
    "\n",
    "best_acc = 0\n",
    "best_c = -1\n",
    "best_gamma = -1\n",
    "\n",
    "for c in [0.1, 1, 5]:\n",
    "    for gamma in [0.1, 1, 5]:\n",
    "        svmModel = SVC(kernel='rbf', gamma=gamma, C=c)\n",
    "        scores = cross_val_score(svmModel, X_trainval_t, Y_trainval, cv=5)\n",
    "        \n",
    "        mean = scores.mean()\n",
    "        \n",
    "        if mean > best_acc:\n",
    "            best_acc = mean\n",
    "            best_c = c\n",
    "            best_gamma = gamma\n",
    "            \n",
    "print(f'Best tuning parameters are c={best_c} and gamma={best_gamma}.')\n",
    "print('Trainval accuracy with these tuning parameters = %.4f.' % best_acc)\n",
    "\n",
    "BestModel = SVC(kernel='rbf', gamma=best_gamma, C=best_c)\n",
    "BestModel.fit(X_trainval_t, Y_trainval)\n",
    "print('Test accuracy with these tuning parameters = %.4f' % BestModel.score(X_test_t, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: \n",
    "Coding not required. You can upload handwritten answer for this part if needed.\n",
    "Consider dataset below with just four samples, 2 features (X1, X2) and binary class label Y.\n",
    "\n",
    "Observations:\n",
    "\n",
    "X1=-1, X2=-1, Y=-1\n",
    "\n",
    "X1=-1, X2= 1, Y= 1\n",
    "\n",
    "X1= 1, X2=-1, Y=1\n",
    "\n",
    "X1= 1, X2=1, Y=-1\n",
    "\n",
    "\n",
    "1) Can a linear SVC perfectly slassify the data?\n",
    "\n",
    "2) Suppose we modify the features to be (X1 , X1.X2), i.e we have interaction term instead of just X2. Can a linear SVC work well on the transformed features? Justify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(AP)** I have uploaded my handwritten solutions in a separate file. \n",
    "1. A linear SVC can not perfectly classify the data because it is not linearly separable, so there is no way to draw a line that separates it.\n",
    "2. Yes, a linear SVC can now classify the data. The transformation has resulted in the data being linearly separable now. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
