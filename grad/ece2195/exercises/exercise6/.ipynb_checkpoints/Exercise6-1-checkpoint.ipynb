{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6:  Unbalanced Datasets and Discriminant Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 1)\n",
    "A) The following code generates synthetic data with one feature from two classes using the make_classification function.   Split the data into train and test, then estimate the parameters needed to implement LDA classification. \n",
    "Predict the test data using the LDA discriminant score (you need to write your own implementation for evaluating the discriminant score). Feel free to double-check your answer by comparing with the Scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=1, \\\n",
    "                           n_informative =1, n_redundant =0, \\\n",
    "                           n_classes=2, n_clusters_per_class=1, \\\n",
    "                           n_repeated=0, weights=[0.5], flip_y=0, \\\n",
    "                           random_state=0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# split up classes to calculate mean, variance, and priors\n",
    "c0 = []\n",
    "c1 = []\n",
    "\n",
    "for i, j in zip(X_train, Y_train):\n",
    "    val = i[0]\n",
    "    if j == 0:\n",
    "        c0.append(val)\n",
    "    else:\n",
    "        c1.append(val)\n",
    "\n",
    "c0 = np.asarray(c0)\n",
    "c1 = np.asarray(c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.94.\n"
     ]
    }
   ],
   "source": [
    "# calculate mean, variance, and priors\n",
    "u = [np.mean(c0), np.mean(c1)]                                                # means of classes\n",
    "s = (np.var(c0) + np.var(c1)) / 2                                             # weighted average of all variances\n",
    "pi = [len(c0) / (len(c0) + len(c1)), len(c1) / (len(c0) + len(c1))]           # prior class probabilities\n",
    "\n",
    "# calculate discriminant score for each class\n",
    "preds = []\n",
    "\n",
    "for sample in X_test:\n",
    "    sample = sample[0]\n",
    "    scores = []\n",
    "    \n",
    "    for k in range(0, 2):\n",
    "        score = sample * u[k]/s - u[k]**2/s**2 + np.log(pi[k])\n",
    "        scores.append(score)\n",
    "        \n",
    "    if scores[0] > scores[1]:\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        preds.append(1)\n",
    "\n",
    "acc = np.count_nonzero(preds==Y_test) / len(preds)\n",
    "print('Accuracy is %.2f.' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.94.\n"
     ]
    }
   ],
   "source": [
    "# double check with scikit-learn LDA function\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, Y_train)\n",
    "lda_preds = lda.predict(X_test)\n",
    "lda_acc = np.count_nonzero(lda_preds==Y_test) / len(lda_preds)\n",
    "print('Accuracy is %.2f.' % lda_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) With the same data generated above, Estimate the parameters needed to implement QDA classification. \n",
    "Predict the test data using the QDA discriminant score (you need to write your own implementation for evaluating the discriminant score). Find the accuracy. Feel free to double-check your answer by comparing with the Scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.98.\n"
     ]
    }
   ],
   "source": [
    "s = [np.var(c0), np.var(c1)]    # each class has its own variance now\n",
    "\n",
    "# calculate discriminant score for each class\n",
    "preds = []\n",
    "\n",
    "for sample in X_test:\n",
    "    sample = sample[0]\n",
    "    scores = []\n",
    "    \n",
    "    for k in range(0, 2):\n",
    "        score = -0.5*sample*1/s[k]*sample + sample*1/s[k]*u[k] - 0.5*u[k]*1/s[k]*u[k] -0.5*np.log(s[k]) + np.log(pi[k])\n",
    "        scores.append(score)\n",
    "        \n",
    "    if scores[0] > scores[1]:\n",
    "        preds.append(0)\n",
    "    else:\n",
    "        preds.append(1)\n",
    "\n",
    "acc = np.count_nonzero(preds==Y_test) / len(preds)\n",
    "print('Accuracy is %.2f.' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.98.\n"
     ]
    }
   ],
   "source": [
    "# double check with scikit-learn QDA function\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, Y_train)\n",
    "qda_preds = qda.predict(X_test)\n",
    "qda_acc = np.count_nonzero(qda_preds==Y_test) / len(qda_preds)\n",
    "print('Accuracy is %.2f.' % qda_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2)\n",
    "Use the make_classification function (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) to create an imbalanced dataset for two classes with two features. Example input argument can be: (n_samples=10000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.9], flip_y=0, random_state=0). The weights argument define how imbalaced the data in the classes are.\n",
    "\n",
    "A) After creating the dataset, split it into train and test.  Train a Logistic regression classifier (use solver='lbfgs' and keep the rest with default values) and find its accuracy, precision and recall.  \n",
    "\n",
    "B) Apply a threshold of 0.5 (default) on the probability values obtained via Logisitic regression to make the prediction. Then, find the accuracy, precision and recall. You should obtain the same results as in previous part. (You can use predict_proba method to find the probabilities.)\n",
    "\n",
    "C) Change the threshold to a lower value (e.g. 0.4), and find the accuracy, precision, and recall. Evaluate the precision and recall without using sklearn.metrics. Feel free to double check your results with values obtained from sklearn.metrics library.\n",
    "\n",
    "D) Train a dummy classifier that predict the most frequent class and find its accuracy. (you can use: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "    Select dummy classifier with \"most frequent\" strategy as follows: \n",
    "         - dummy_majority=DummyClassifier(strategy='most_frequent')\n",
    "E) Comment on your results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Precision: 0.94\n",
      "Recall: 0.71\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=2, \\\n",
    "                           n_redundant =0, \\\n",
    "                           n_clusters_per_class=1, \\\n",
    "                           weights=[0.9], flip_y=0, \\\n",
    "                           random_state=0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "LogRegModel = LogisticRegression(solver='lbfgs')\n",
    "LogRegModel.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = LogRegModel.predict(X_test)\n",
    "\n",
    "# Only do for positive class (label=1)\n",
    "print('Accuracy: %.2f' % LogRegModel.score(X_test, Y_test))\n",
    "print(f'Precision: %.2f' % precision_score(Y_test, Y_pred))\n",
    "print(f'Recall: %.2f' % recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD = 0.5.\n",
      "Accuracy: 0.97\n",
      "Precision for class 1: 0.94\n",
      "Recall for class 1: 0.71\n",
      "\n",
      "\n",
      "THRESHOLD = 0.4.\n",
      "Accuracy: 0.97\n",
      "Precision for class 1: 0.96\n",
      "Recall for class 1: 0.70\n",
      "\n",
      "\n",
      "THRESHOLD = 0.3.\n",
      "Accuracy: 0.97\n",
      "Precision for class 1: 0.97\n",
      "Recall for class 1: 0.68\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = LogRegModel.predict_proba(X_test)\n",
    "\n",
    "thresholds = [0.5, 0.4, 0.3]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f'THRESHOLD = {threshold}.')\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "\n",
    "    for prob, val in zip(probs, Y_test):\n",
    "        if prob[0] > threshold: # prediction is 0\n",
    "            if val == 0:\n",
    "                tn += 1\n",
    "            else:               # real value is 1\n",
    "                fn += 1\n",
    "        else:                   # prediction is 1\n",
    "            if val == 0:     \n",
    "                fp += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp)\n",
    "    rec = tp / (tp + fn)\n",
    "\n",
    "    print('Accuracy: %.2f' % acc)\n",
    "    print('Precision: %.2f' % prec)\n",
    "    print('Recall: %.2f' % rec)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, Y_train)\n",
    "\n",
    "print('Accuracy: %.2f' % dummy.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(AP)** Since the dummy classifier has an accuracy around 0.91, just relying on the accuracy for the logistic regression classifier is not sufficient for this unbalanced dataset. The precision and recall metrics for each class are more useful for evaluating its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3) \n",
    "In this part, we will use the handwritten digits data set of Scikit-learn (load_digits). Run the code below. Read the description of the data set and check a sample image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "[ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
      "  3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
      " 16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
      "  0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "DigitsData=load_digits()\n",
    "print(DigitsData.keys()) \n",
    "print(DigitsData.DESCR) #read description of the dataset\n",
    "print(DigitsData.data[1])\n",
    "\n",
    "#plot one of the images in the data\n",
    "plt.gray() \n",
    "plt.matshow(DigitsData.images[1]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Our objective is to build classfiers that identify digit 9. For this purpose, answer the following:\n",
    "\n",
    " Define the target value to be equal to 1 (or True) only for digit 9, and 0 (or False) otherwise.\n",
    "You can define: y= (DigitsData.target == 9)\n",
    "\n",
    "\n",
    "- Find how many times y is equal to 9 and how many times it is not equal to 9\n",
    "\n",
    "what do you observe? Is the dataset for this classification problem balanced or not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times y is equal to 9: 180.\n",
      "Number of times y is not equal to 9: 1617.\n"
     ]
    }
   ],
   "source": [
    "y = np.array((DigitsData.target == 9),dtype=int)\n",
    "\n",
    "t = np.count_nonzero(y==True)\n",
    "f = np.count_nonzero(y==False)\n",
    "\n",
    "print(f'Number of times y is equal to 9: {t}.')\n",
    "print(f'Number of times y is not equal to 9: {f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(AP)** The dataset is not balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Find the accuracy of a dummy classifier (imported below) that always selects the majority class. Use the DigitsData.data as features and y (defined above) as the response.\n",
    "\n",
    "- Use train_test_split with random_state= 0 for splitting the data\n",
    "- Select dummy classifier with \"most frequent\" strategy as follows: \n",
    "    - dummy_majority=DummyClassifier(strategy='most_frequent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "X = DigitsData.data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "dummy.fit(X_train, Y_train)\n",
    "\n",
    "print('Accuracy: %.2f' % dummy.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Instead of a dummy classifier, use an LDA classifer (with default threshold) to solve the above classification problem. Find accuracy, confusion matrix, precision, and recall\n",
    "\n",
    "- Note: you may get a warning that features are correlated (collinear). However, we can still get the performance metrics as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.96.\n",
      "[[394   9]\n",
      " [  7  40]]\n",
      "Precision is 0.82.\n",
      "Recall is 0.85.\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train, Y_train)\n",
    "lda_preds = lda.predict(X_test)\n",
    "\n",
    "print('Accuracy is %.2f.' % accuracy_score(Y_test, lda_preds))\n",
    "print(confusion_matrix(Y_test, lda_preds))\n",
    "print(f'Precision is %.2f.' % precision_score(Y_test, lda_preds))\n",
    "print(f'Recall is %.2f.' % recall_score(Y_test, lda_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Use QDA classifer to perform the classification. Find accuracy, confusion matrix, precision, and recall.\n",
    "- Note: expect to see a warning that features are correlated (collinear). You can still get performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.76.\n",
      "[[299 104]\n",
      " [  2  45]]\n",
      "Precision is 0.30.\n",
      "Recall is 0.96.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avery Peiffer\\anaconda3_new\\lib\\site-packages\\sklearn\\discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "qda.fit(X_train, Y_train)\n",
    "qda_preds = qda.predict(X_test)\n",
    "\n",
    "print('Accuracy is %.2f.' % accuracy_score(Y_test, qda_preds))\n",
    "print(confusion_matrix(Y_test, qda_preds))\n",
    "print(f'Precision is %.2f.' % precision_score(Y_test, qda_preds))\n",
    "print(f'Recall is %.2f.' % recall_score(Y_test, qda_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) From the prediction of the QDA, plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x1e2146bb7f0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(qda, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
