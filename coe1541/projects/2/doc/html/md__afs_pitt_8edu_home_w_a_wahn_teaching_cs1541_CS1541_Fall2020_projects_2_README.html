<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>CS/COE 1541 Project 2: README</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">CS/COE 1541 Project 2
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">README </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a href="#cs-coe-1541---introduction-to-computer-architecture">CS/COE 1541 - Introduction to Computer Architecture</a></li>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#description">Description</a></li>
<li><a href="#processor-design">Processor Design</a></li>
</ul>
</li>
<li><a href="#building-and-running">Building and Running</a><ul>
<li><a href="#environment-setup">Environment Setup</a></li>
<li><a href="#directory-structure-and-makefile-script">Directory Structure and Makefile Script</a></li>
<li><a href="#program-output">Program Output</a></li>
<li><a href="#creating-performance-plots">Creating Performance Plots</a></li>
</ul>
</li>
<li><a href="#configuration-files-and-trace-files">Configuration Files and Trace Files</a><ul>
<li><a href="#configuration-files">Configuration Files</a></li>
<li><a href="#trace-files">Trace Files</a></li>
</ul>
</li>
<li><a href="#your-tasks">Your Tasks</a><ul>
<li><a href="#task-1-enforcing-stalls-and-flushes-on-hazards">Task 1: Enforcing Stalls and Flushes on Hazards</a><ul>
<li><a href="#structural-hazards">Structural hazards</a></li>
<li><a href="#data-hazards">Data hazards</a></li>
<li><a href="#control-hazards">Control hazards</a></li>
</ul>
</li>
<li><a href="#task-2-enabling-optimizations-on-the-hazards">Task 2: Enabling Optimizations on the Hazards</a></li>
<li><a href="#task-3-analyzing-performance-plots">Task 3: Analyzing Performance Plots</a></li>
<li><a href="#source-code">Source Code</a></li>
<li><a href="#submission">Submission</a></li>
</ul>
</li>
<li><a href="#resources">Resources</a></li>
</ul>
<h1>CS/COE 1541 - Introduction to Computer Architecture</h1>
<p>Fall Semester 2020 - Project 1</p>
<ul>
<li>Source Code DUE: Oct 15 (Thursday), 2020 5:00 PM (2 day extension)</li>
<li>Retrospective DUE: Oct 20 (Tuesday), 2020 5:00 PM</li>
</ul>
<h1>Introduction</h1>
<h2>Description</h2>
<p>The goal of this project is to create a software simulator for a simplified 2-wide in-order processor architecture. So why do architects build simulators before creating the actual hardware design?</p>
<ol type="1">
<li>Simulators allow them to test out the performance of various designs and parameters before building the real chip. Designing a chip, verifying it, and fabricating it is hugely expensive and time consuming. But software simulators allow hundreds of different combinations of designs and parameters to be tried out by simply modifying the simulator configuration file. These designs are tested against multiple benchmarks to measure their relative performances. Some popular ones are <a href="https://www.spec.org/benchmarks.html">SPEC Benchmark</a>, <a href="http://www.netlib.org/benchmark/hpl/">LINPACK Benchmark</a>, and <a href="https://www.nas.nasa.gov/publications/npb.html">NAS Parallel Benchmark</a>. Benchmarks that reflect the applications that the processor is targeted for are prioritized.</li>
</ol>
<ol type="1">
<li>Simulators not only provide information about speed but also other considerations, one major one being power consumption. The end of Dennard Scaling and the subsequent Power Wall has made measuring power consumption an indispensable part of processor design. Power models such as the <a href="https://en.wikipedia.org/wiki/SPICE">SPICE Model</a> allow architects to estimate the power use of circuits. Simulators can also emulate the effects of variability in the processor manufacturing process and how it effects the end product. Simulators are also used to measure the reliability of processors by emulating what happens when temperature hotspots form or bit flips are caused by cosmic radiation.</li>
</ol>
<ol type="1">
<li>Simulators also expose a lot of corner cases and bugs in a design before going to the fab. Building a simulator forces an architect to implement in some detail (albeit in software) the ideas he/she had and see it in motion, not just on a piece of paper. For example, if your simulator falls into an infinite loop, it is very likely your hardware design will too! Hardware designs are increasingly parallel nowadays, and just like parallel software dataraces, hardware can also have hardware races. A prime source of bugs is the cache coherence protocol, that is, how do you keep caches in multiple cores coherent with each other when the cores are updating data in parallel. The higher the fidelity of the simulator to the actual hardware design, the higher the chance of finding defects.</li>
</ol>
<p>You will build your simulator with similar goals in mind. You will identify the structural, data, and control hazards present in your processor design, implement the necessary pipeline stalls and flushes required to avoid them, and measure the impact they have on performance. Next, you will implement optimizations to the design that can avoid those stalls and flushes and evaluate them too.</p>
<h2>Processor Design</h2>
<p>The simplified 2-wide processor pipeline that you will simulate has the following basic structure:</p>
<div class="image">
<img src="Project1_diagram.png"  alt="Pipeline" width="700"/>
</div>
<p>The processor can fetch two instructions at a time, decode two instructions at a time, and also writeback the results two at a time, which is why it is called a 2-wide processor. For the EX stage, instructions are routed to two different execution units depending on the instruction type. Lw (load word) and sw (store word) instructions are routed to the lw/sw EX unit and all instructions other than lw/sw are routed to the ALU/Branch EX unit. Lw/sw instructions also pass through a MEM unit that performs the load or store. ALU/Branch instructions don't require a MEM unit but they pass through an "empty" pipeline stage nonetheless so that both lw/sw and ALU/Branch instructions can perform WB at the same stage. Having WB, or register writeback, at the same stage simplifies processor design (for example, allowing less write ports in the register file).</p>
<p>The fact that each individual EX unit can process only certain types of instructions can lead to situations where the pipeline is not filled (bubbles). For example, if the ID stage is filled with two ALU/Branch instructions then at the next clock cycle, only one of those instructions will be routed to the ALU/Branch EX unit and the lw/sw EX unit must sit idle. Also, the remaining ALU/Branch instruction needs to wait one more cycle before being routed. The act of routing an instruction to the correct EX unit in computer architecture parlance is called <b>issuing</b> an instruction.</p>
<p>Now, given the above situation, you may be tempted to dynamically reorder instructions such that the ID stage is not filled with two instructions of the same type so that the processor can issue to both EX units at each cycle. This is called dynamic scheduling, as we learned in class. With dynamic scheduling, the processor would queue up many instructions at the ID stage (called the <b>issue queue</b>) such that the processor has a large window of instructions with a high probability that there is an instruction to issue for each EX unit at each cycle. This type of processor is called an <b>out-of-oder</b> processor since it has the ability to issue instructions out of original program order. But in order to do this, the processor needs to do complex dynamic data dependence analysis to make sure that the reorderings are legal. We cannot properly implement an out-of-order processor within the time constraints of this class, so we will implement an in-order processor instead.</p>
<p>An <b>in-order</b> processor issues instructions strictly in program order. Thus, it avoids violating data dependences in the program in a simplified way. That means the issue queue operates like an actual queue (first-in-first-out). The queue order is the program order. In this organization, it does not make sense to have a queue length longer than the issue width, since the processor will at most be looking at two instructions at a time. Hence, the queue length is two, equal to ths width of the processor.</p>
<h1>Building and Running</h1>
<h2>Environment Setup</h2>
<p>The project is setup to run with the g++ compiler (GNU C++ compiler) and a Make build system. This system is already in place on the departmental Linux machines (linux.cs.pitt.edu). If you have a similar setup on your local computer, please feel free to use your machine for development. Otherwise, you need log in to linux.cs.pitt.edu which may involve some setup. Here are the steps you need to take:</p>
<ol type="1">
<li>If you haven't already, install Pulse VPN Desktop Client. Instructions on how to download and use: <a href="https://www.technology.pitt.edu/services/pittnet-vpn-pulse-secure">https://www.technology.pitt.edu/services/pittnet-vpn-pulse-secure</a> Then, set up the VPN client and connect to Pitt VPN as follows: <a href="https://www.technology.pitt.edu/help-desk/how-to-documents/pittnet-vpn-pulse-secure-connect-pulse-secure-client">https://www.technology.pitt.edu/help-desk/how-to-documents/pittnet-vpn-pulse-secure-connect-pulse-secure-client</a></li>
<li>Most OSes (Windows, MacOS, Linux) comes with built-in SSH clients accessible using this simple command on your commandline shell: ``` ssh <a href="#" onclick="location.href='mai'+'lto:'+'USE'+'RN'+'AME'+'@l'+'inu'+'x.'+'cs.'+'pi'+'tt.'+'ed'+'u'; return false;">USERN<span style="display: none;">.nosp@m.</span>AME@<span style="display: none;">.nosp@m.</span>linux<span style="display: none;">.nosp@m.</span>.cs.<span style="display: none;">.nosp@m.</span>pitt.<span style="display: none;">.nosp@m.</span>edu</a> ``` If you want a more fancy SSH client, you can download Putty, a free open source terminal: <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html</a> Connect to "linux.cs.pitt.edu" by typing that in the "Host Name" box. Make sure that port is 22 and SSH is selected in the radio button options.</li>
<li>Once connected, the host will ask for your Pitt SSO credentials. Enter your ID and password.</li>
<li>Once logged in, check your quota by typing "fs lq": ``` $ fs lq Volume Name Quota Used Used Partition u.wahn 2547712 1543899 61% 85% ``` This shows your quota in KBs. The above shows 2.5 GBs. This project will require at least 50 MBs of disk space. If you don't have that much remaining please contact my.pitt.edu to increase it. By default, students are given a paltry 5 MBs of space so it is likely that you don't have the space. I have been told that you can be given up to 2 GBs of space if you ask for it. The fastest way to contact my.pitt.edu is through the <b>live chat</b> on the website. It should just take a minute or two.</li>
</ol>
<p>The project files are within the directory /afs/cs.pitt.edu/courses/1541/project1 once you are logged in to linux.cs.pitt.edu. Identical files are also on this GitHub folder. Copy the project files to a working directory of your choice and cd into that directory.</p>
<h2>Directory Structure and Makefile Script</h2>
<p>Here is an overview of the directory structure:</p>
<p>``` config.c / <a class="el" href="config_8h_source.html">config.h</a> : Functions used to parse and read in the processor configuration file. CPU.c / <a class="el" href="CPU_8h_source.html">CPU.h</a> : Implements the five stages of the processor pipeline. The code you will be <b>modifying</b>. five_stage.c : Main function. Parses commandline arguments and invokes the five stages in CPU.c at every clock cycle. trace.c / <a class="el" href="trace_8h_source.html">trace.h</a> : Functions to read and write the trace file. trace_generator.c : Utility program to generate a trace file of your own. trace_reader.c : Utility program to read and print out the contents of a trace file in human readable format. Makefile : The build script for the Make tool. five_stage_solution : <b>Reference solution binary</b> for the project. generate_plot.plt : GNUPlot script to generate the plot PDF file from the data. generate_plot.py: Python script to extrace performance data from results in tabular form. confs/ : Directory where processor configuration files are. diffs/ : Directory with diffs between outputs/ and outputs_solution/ are stored. outputs/ : Directory where outputs after running five_stage are stored. outputs_solution/ : Directory where outputs produced by five_stage_solution are stored. plot_confs/ : Directory where processor configurations for the plot generation are. plots/ : Directory where outputs after running five_stage are stored for plot generation. plots_solution/ : Directory where outputs after running five_stage_solution are stored for plot generation. traces/ : Directory where instruction trace files used to test the simulator are stored. ```</p>
<p>In order to build the project and run the simulations, you only need to do 'make' to invoke the 'Makefile' script:</p>
<p>``` $ make g++ -c -g -Wall -I/usr/include/glib-2.0/ -I/usr/lib64/glib-2.0/include/ five_stage.c g++ -c -g -Wall -I/usr/include/glib-2.0/ -I/usr/lib64/glib-2.0/include/ config.c g++ -c -g -Wall -I/usr/include/glib-2.0/ -I/usr/lib64/glib-2.0/include/ CPU.c g++ -c -g -Wall -I/usr/include/glib-2.0/ -I/usr/lib64/glib-2.0/include/ trace.c ... ```</p>
<p>If successful, it will produce the binaries: five_stage, trace_generator, and trace_reader as well as results of the simulation using all combinations of 4 configuration files and 8 trace files. A configuration file represents a processor design and a trace file contain instructions from a micro-benchmark, so you will be in effect simulating 4 processor designs on a benchmark suite. You can generate your own traces using the trace_generator and put it inside the traces/ directory or create a new configuration inside the confs/ directory, and they will be incorporated into the results automatically by the Makefile script. The results are stored in the outputs/ directory and also side-by-side diffs with the outputs_solution/ directory are generated and stored in the diffs/ directory. When you debug the program, you will find these side-by-side diffs useful.</p>
<p>If you only wish to build your C files and not run the simulations, just do 'make build' to invoked the 'build' target in the 'Makefile' script:</p>
<p>``` $ make build ```</p>
<p>If you wish to remove all files generated from your five_stage implementation (object files and experiment output), invoke the 'clean' target:</p>
<p>``` $ make clean ```</p>
<p>If you wish to remove all generated files (including ones generated from five_stage_solution), invoke the 'distclean' target:</p>
<p>``` $ make distclean ```</p>
<p>You can also run your simulator on more sizable benchmarks. I have 4 short and 2 long trace files: (sample1.tr, sample2.tr, sample3.tr, sample4.tr) and (sample_large1.tr, sample_large2.tr). These files are accessible at /afs/cs.pitt.edu/courses/1541/long_traces and /afs/cs.pitt.edu/courses/1541/short_traces. But these are not incorporated into the Makefile default target because they take significantly longer to run. When you do run these on five_stage, I recommend you do not have the -v (verbose) or -d (debug) flags on or the simulations will take too long and the output may overflow your disk space.</p>
<h2>Program Output</h2>
<p>You are given a program, five_stage.c, which reads a trace file (a binary file containing a sequence of executed instructions) and simulates a 5 stage pipeline ignoring any control and data hazards. It outputs the total number of cycles needed to execute the instructions in the trace file and, also calculates the IPC (Instructions Per Cycle):</p>
<p>``` $ ./five_stage -t traces/sample.tr -c confs/2-wide.conf</p>
<ul>
<li>Number of cycles : 804</li>
<li>IPC (Instructions Per Cycle) : 1.2438 ```</li>
</ul>
<p>The IPC is the measure of performance for the processor design.</p>
<p>If the -v (verbose) option is given on the commandline, instructions that enter the pipeline (IF) and instructions that exit the pipeline (WB), along with corresponding clock cycles, are printed:</p>
<p>``` ./five_stage -t traces/sample.tr -c confs/2-wide.conf -v [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [1: IF] LOAD: (Seq: 1)(Regs: 16, 29, 255)(Addr: 2147450880)(PC: 2097312) [1: IF] ITYPE: (Seq: 2)(Regs: 28, 255, 255)(Addr: 4097)(PC: 2097316) [2: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [2: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [2: IF] ITYPE: (Seq: 3)(Regs: 28, 28, 255)(Addr: -16384)(PC: 2097320) [2: IF] ITYPE: (Seq: 4)(Regs: 17, 29, 255)(Addr: 4)(PC: 2097324) [3: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [3: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [3: IF] ITYPE: (Seq: 5)(Regs: 3, 17, 255)(Addr: 4)(PC: 2097328) [3: IF] ITYPE: (Seq: 6)(Regs: 2, 255, 16)(Addr: 2)(PC: 2097332) ... ```</p>
<p>The format of one line in the printout is as follows. For example, let's take this line:</p>
<p>``` [1: IF] LOAD: (Seq: 1)(Regs: 16, 29, 255)(Addr: 2147450880)(PC: 2097312) ```</p>
<ul>
<li>[1: IF] - This says an instruction entered the pipeline at cycle 1 by being fetched at the IF stage.</li>
<li>LOAD - This says that instruction was a LOAD type instruction.</li>
<li>(Seq: 1) - This says this instruction was sequence number 1 in the trace file (i.e. first instruction in the file).</li>
<li>(Regs: 16, 29, 255) - This says registers dst, src1, src2 were 16, 29, 255 respectively. LOAD instructions do not use the src2 register so it is set to 255 (-1 in signed byte integer).</li>
<li>(Addr: 2147450880) - This says the LOAD instruction read address 2147450880 in memory.</li>
<li>(PC: 2097312) - The PC (program counter, or instruction pointer) was 2097312 when the trace was generated.</li>
</ul>
<p>If the -d (debug) option is given on the commandline, the internal state of pipeline stages is printed at every clock cyle, which can be useful for debugging your simulator. The -v option is implied by the -d option. The Makefile script uses the -d option to generate outputs. You can open the generated output file after building:</p>
<p>``` $ nano outputs/sample.2-wide.out ```</p>
<p>Or, you can run with the -d option yourself:</p>
<p>``` $ ./five_stage -t traces/sample.tr -c confs/2-wide.conf -d ```</p>
<p>And you should see the following output:</p>
<p>``` [CYCLE NUMBER: 1] [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [1: IF] LOAD: (Seq: 1)(Regs: 16, 29, 255)(Addr: 2147450880)(PC: 2097312) </p>
<h1>[1: IF] ITYPE: (Seq: 2)(Regs: 28, 255, 255)(Addr: 4097)(PC: 2097316) </h1>
<p>Pipeline Stage NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_lwsw NOP: (Seq: 0)(Regs: 0, 0, 0) EX_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) EX_lwsw NOP: (Seq: 0)(Regs: 0, 0, 0) ID NOP: (Seq: 0)(Regs: 0, 0, 0) ID LOAD: (Seq: 1)(Regs: 16, 29, 255) IF </p>
<h1>ITYPE: (Seq: 2)(Regs: 28, 255, 255) IF </h1>
<p>... ```</p>
<p>If you see [CYCLE NUMBER: 1] on the above printout, you will see that instructions LOAD and ITYPE are at the IF stage because they have just been fetched. Remember that this is a 2-wide processor so we are able to process two instructions per cycle.</p>
<p>``` ... [CYCLE NUMBER: 2] [2: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [2: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [2: IF] ITYPE: (Seq: 3)(Regs: 28, 28, 255)(Addr: -16384)(PC: 2097320) </p>
<h1>[2: IF] ITYPE: (Seq: 4)(Regs: 17, 29, 255)(Addr: 4)(PC: 2097324) </h1>
<p>Pipeline Stage NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_lwsw NOP: (Seq: 0)(Regs: 0, 0, 0) EX_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) EX_lwsw LOAD: (Seq: 1)(Regs: 16, 29, 255) ID ITYPE: (Seq: 2)(Regs: 28, 255, 255) ID ITYPE: (Seq: 3)(Regs: 28, 28, 255) IF </p>
<h1>ITYPE: (Seq: 4)(Regs: 17, 29, 255) IF </h1>
<p>... ```</p>
<p>At [CYCLE NUMBER: 2], the LOAD and ITYPE instructions are now at the ID stage.</p>
<p>``` ... [CYCLE NUMBER: 3] [3: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [3: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [3: IF] ITYPE: (Seq: 5)(Regs: 3, 17, 255)(Addr: 4)(PC: 2097328) </p>
<h1>[3: IF] ITYPE: (Seq: 6)(Regs: 2, 255, 16)(Addr: 2)(PC: 2097332) </h1>
<p>Pipeline Stage NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) MEM_lwsw ITYPE: (Seq: 2)(Regs: 28, 255, 255) EX_ALU LOAD: (Seq: 1)(Regs: 16, 29, 255) EX_lwsw ITYPE: (Seq: 3)(Regs: 28, 28, 255) ID ITYPE: (Seq: 4)(Regs: 17, 29, 255) ID ITYPE: (Seq: 5)(Regs: 3, 17, 255) IF </p>
<h1>ITYPE: (Seq: 6)(Regs: 2, 255, 16) IF </h1>
<p>... ```</p>
<p>At [CYCLE NUMBER: 3], you will see that the order of LOAD and ITYPE has been flipped to ITYPE and LOAD. This is not a change in the ordering in any sense. For the EX stage, the top row (EX_ALU) refers to the ALU/Branch EX unit and the bottom row (EX_lwsw) refers to the lw/sw EX unit. Since ITYPE belongs to the former and LOAD belongs to the latter, that's why the ordering changed. The same applies to the MEM stage.</p>
<p>``` ... [CYCLE NUMBER: 4] [4: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [4: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) </p>
<h1>[4: IF] RTYPE: (Seq: 7)(Regs: 3, 3, 2)(Addr: 0)(PC: 2097336) </h1>
<p>Pipeline Stage NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) WB ITYPE: (Seq: 2)(Regs: 28, 255, 255) MEM_ALU LOAD: (Seq: 1)(Regs: 16, 29, 255) MEM_lwsw ITYPE: (Seq: 3)(Regs: 28, 28, 255) EX_ALU NOP: (Seq: 0)(Regs: 0, 0, 0) EX_lwsw ITYPE: (Seq: 4)(Regs: 17, 29, 255) ID ITYPE: (Seq: 5)(Regs: 3, 17, 255) ID ITYPE: (Seq: 6)(Regs: 2, 255, 16) IF </p>
<h1>RTYPE: (Seq: 7)(Regs: 3, 3, 2) IF </h1>
<p>... ```</p>
<p>At [CYCLE NUMBER: 4], we see our first bubble. This is due to a structural hazard on the ALU/Branch EX unit. There were two ITYPE instructions ready to issue in the ID stage at the previous cycle, but since there is only one ALU/Branch EX unit, only one could issue. The lw/sw EX unit is filled with a NOP bubble.</p>
<p>In this way, you can analyze the output to make sure that various pipeline hazards are handled properly and also your optimizations work properly. Again, there is a set of reference outputs under the outputs_solution/ directory and diffs in the diffs/ directory that you can also analyze to figure out what you did wrong.</p>
<p>Now, the simulator can also be run with a 1-wide processor configuration (see next section <a href="#configuration-files">Configuration Files</a>). Let's take a brief look at the output for that configuration:</p>
<p>``` $ nano outputs/sample.1-wide.out ```</p>
<p>You will see the following:</p>
<p>``` [CYCLE NUMBER: 1] [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) [1: WB] NOP: (Seq: 0)(Regs: 0, 0, 0)(Addr: 0)(PC: 0) </p>
<h1>[1: IF] LOAD: (Seq: 1)(Regs: 16, 29, 255)(Addr: 2147450880)(PC: 2097312) </h1>
<p>Pipeline Stage NOP: (Seq: 0)(Regs: 0, 0, 0) WB NOP: (Seq: 0)(Regs: 0, 0, 0) MEM NOP: (Seq: 0)(Regs: 0, 0, 0) EX NOP: (Seq: 0)(Regs: 0, 0, 0) ID </p>
<h1>LOAD: (Seq: 1)(Regs: 16, 29, 255) IF </h1>
<p>... ```</p>
<p>Since the processor is now 1-wide, there is only each of IF, ID, EX, MEM, and WB stages per cycle. The EX stage may be the ALU/Branch EX unit or the lw/sw EX unit depending upon the instruction type. Since only one of either can be active at a time, only one is shown.</p>
<h2>Creating Performance Plots</h2>
<p>If you copied over the project files on or before Sep. 27, you will have to update the following files that were created anew:</p>
<p>``` Makefile generate_plot.plt generate_plot.py plot_confs/ plots/ plots_solution/ ```</p>
<p>None of these are source files that you were asked to modify, so it shouldn't disrupt your work in any way.</p>
<p>Once, you have those files updated, you will see the Makefile has a new target: plots.</p>
<p>``` $ make plots ```</p>
<p>The above command will create two files: IPC.pdf and IPC_solution.pdf. The two files show the IPCs for the short traces in /afs/cs.pitt.edu/courses/1541/short_traces for the various processor configurations under plot_confs/, for your five_stage binary and the five_stage_solution binary respectively.</p>
<p>If you open IPC_solution.pdf, you will see 8 bars (results of running each of the 4 short traces on a 1-wide processor and a 2-wide processor). Each bar is a histogram with 5 component bars stacked up:</p>
<ul>
<li>no optimization: IPC of a processor with no optimizations to avoid hazards</li>
<li>enableForwarding: Additional IPC gain when enableForwarding is set to true in the configuration file</li>
<li>branchPredictor: Additional IPC gain when branchPredictor and branchTargetBuffer are set to true in the configuration file</li>
<li>splitCaches: Additional IPC gain when splitCaches is set to true in the configuration file</li>
<li>regFileWritePorts=2: Additional IPC gain when regFileWritePorts is increased to 2 (from 1) in the configuration file</li>
</ul>
<p>Each optimization is turned on incrementally in the order listed above and the IPC gain measured.</p>
<p>Now IPC.pdf (the plot generated from your five_stage) initially will look very different from IPC_solution.pdf. It will show no components pertaining to IPC gains due to optimizations because the optimizations have yet to be implemented. Also, the IPCs will be higher because bubbles due to hazards have not been implemented either. But once you are done and you pass all the diff tests, your plot should look identical to the solution plot.</p>
<h1>Configuration Files and Trace Files</h1>
<h2>Configuration Files</h2>
<p>You can find 4 configuration files under the confs/ directory. Each will configure a different processor when passed as the -c option to five_stage. The files are: 1-wide.conf, 1-wide-opt.conf, 2-wide.conf, 2-wide-opt.conf.</p>
<ul>
<li>1-wide.conf : Configuration for a 1-wide processor that fetches and decodes only one instruction per cycle. Similar to the classic five stage pipeline we discussed extensively in class, except that instructions are issued to different EX units depending on type.</li>
<li>1-wide-opt.conf : Configuration for a 1-wide processor with all hazard avoiding hardware optimizations enabled such as data forwarding.</li>
<li>2-wide.conf : Configuration for the 2-wide processor described above.</li>
<li>2-wide-opt.conf : Configuration for the 2-wide processor with hazard avoiding enabled.</li>
</ul>
<p>Here is how the 2-wide-opt.conf file looks like:</p>
<p>``` [pipeline]</p>
<p>width=2</p>
<p>[structural hazard]</p>
<p>splitCaches=true regFileWritePorts=2</p>
<p>[data hazard]</p>
<p>enableForwarding=true</p>
<p>[control hazard]</p>
<p>branchPredictor=true branchTargetBuffer=true ```</p>
<p>Here is what each of those items mean:</p>
<ul>
<li>width=2 : It is a 2-wide processor.</li>
<li>splitCaches=true : The processor has split caches: one data cache and one instruction cache. This means all structural hazards between the MEM and IF stages can be resolved without stalling.</li>
<li>regFileWritePorts=2 : The register file has two write ports. This means that when two instructions at the WB stage both need to write to the register file, they do not need to stall.</li>
<li>enableForwarding=true : The processor has data forwarding so that instructions with data dependencies do not need to stall until writeback of the register value. An exception we learned in class is use-after-load where a register use immediately after a load to that register need to stall one cycle.</li>
<li>branchPredictor=true : The processor has a branch predictor (essentially a Branch History Table) that can predict the direction of a branch. 100% prediction rate is assumed. On a predicted taken branch, instructions can start to be fetched after the ID stage when the branch target address is decoded, instead of the EX stage when the branch condition is evaluated. On a predicted not taken branch, instructions can start to be fetched immediately after the IF stage since the branch target is not needed.</li>
<li>branchTargetBuffer=true : The processor has a Branch Target Buffer that can predict the branch target as well as the direction. Again 100% prediction rate is assumed. Now instruction can start to be fetched immediately after the IF stage regardless of taken or not taken because the target can be predicted at IF even before decoding.</li>
</ul>
<h2>Trace Files</h2>
<p>You can find 8 trace files under the traces/ directory. Most of them test whether you handled a hazard correctly.</p>
<ul>
<li>structural_memory.tr : Structural hazard on the memory read port involving the LOAD MEM stage and another instruction's IF stage.</li>
<li>structural_regfile.tr : Structural hazard on the register file write port involving an RTYPE and a LOAD instruction both writing to the register file.</li>
<li>data_load_use.tr : Contains a LOAD followed by an RTYPE (register only) instruction dependent on the load, representing a data hazard.</li>
<li>data_raw.tr : Another data hazard but this type an RTYPE followed by a dependent RTYPE instruction. The dependency is RAW (Read After Write).</li>
<li>data_waw.tr : Again a data hazard with an RTYPE and a LOAD instruction both writing to the same register. the dependency is WAW (Write After Write). Note this is different from structural_regfile.tr in that increasing the register write ports would not solve this problem.</li>
<li>control_taken.tr : Control hazard on a taken BRANCH instruction followed by a couple of other instructions.</li>
<li>control_non_taken.tr : A not taken BRANCH instruction followed by a couple of other instructions. Since our processor just keeps on fetching instructions after a branch anyway this is technically not a hazard. But it's there to make sure you are able to differentiate taken and not taken branches.</li>
<li>sample.tr : A moderately long trace of instructions (681 instructions) that contain various hazards.</li>
</ul>
<h1>Your Tasks</h1>
<h2>Task 1: Enforcing Stalls and Flushes on Hazards</h2>
<p>Our five_stage simulator at its current state does not deal with hazards and hence does not simulate correct execution. The performance numbers you are seeing are overly optimistic. Emulate what a Hazard Detection Unit (HDU) would do and inject bubbles into your pipeline where pipeline stalls or flushes are required to handle a hazard. At this point, assume that all hazard avoidance optimizations are omitted (i.e. we are using the 2-wide.conf or the 1-wide.conf configuration). Specifically handle the following hazards.</p>
<h3>Structural hazards</h3>
<p>I have already handled one structural hazard for you: the one on EX units when two instructions in the ID stage need to be issued to the same EX unit. The solution was to stall and have the later instruction wait one cycle before issuing. And these stalls single-handedly brought down the IPC of the 2-wide processor from 2 to 1.2438!</p>
<p>``` $ make ... $ grep IPC outputs/sample.2-wide* outputs/sample.2-wide-opt.out:+ IPC (Instructions Per Cycle) : 1.2438 outputs/sample.2-wide.out:+ IPC (Instructions Per Cycle) : 1.2438 ```</p>
<p>IPC of 2 is the ideal number for a 2-wide processor and the current implementation inserts no bubbles except for the above hazard. And that is also why because 2-wide-opt and 2-wide produce the same IPC: because the hazard avoidance optimizations don't have effect when there are no hazards to begin with.</p>
<p>There are two additional structural hazards that I want you to implement:</p>
<ul>
<li>The structural hazard on memory read ports: When a LOAD (lw) instruction is at the MEM stage where it reads from memory it is in contention with the IF stage of a later instruction which also reads from memory to fetch instructions. In this case, the HDU must delay all instruction fetches (both of them) one cycle until the lw MEM stage is over. Note that a STORE (sw) instruction does not matter because it uses the write port of memory.</li>
<li>The structural hazard on register file write ports: When a LOAD instruction and an ALU instruction both attempt to write to the register file at the WB stage, there is a structural hazard on the write port, if there is only one. In this case, the contention should be resolved by having the older instruction go first while the younger remains in the MEM stage.</li>
</ul>
<h3>Data hazards</h3>
<p>In our processor, data dependencies through memory don't cause data hazards because all instructions execute in-order and there is only one MEM unit. Basically, even if there is a LOAD that immediately follows a STORE accessing the same memory location, the value would already be in memory by the time the LOAD gets to the MEM stage. Hence, all data hazards occur through registers. Specifically:</p>
<ul>
<li>RAW (Read After Write) hazards: This is when an instruction reads a register written by a previous instruction, and there is a possibility that the ordering can be flipped or happen simultaneously. With no data forwarding, stalls due to RAW hazards happen at the ID stage since that is the stage when registers are read from the register file. If there is a data hazard, the ID stage would be cancelled and the instruction would wait at the IF stage. Only when the data hazard is resolved is the instruction allowed to proceed to the ID stage and read registers. With data forwarding, stall happen at the EX stage since that is the stage where values are forwarded. If there is a data hazard, the EX stage is canceled and the instruction will wait until the forwarded value is available.<ul>
<li>Use-after-load hazards: This is a special case of a RAW hazard where the register writing instruction is a LOAD instruction. This is more problematic because LOAD produces the value at the MEM stage (whereas ALU instructions produce the value at the EX stage), so even with data forwarding, you need a stall as we learned in class. But without forwarding, it is the same as any RAW hazard since all registers are written back on the WB stage anyway.</li>
</ul>
</li>
<li>WAW (Write After Write) hazards: This is when an instruction writes to a register written by a previous instruction. The ordering will never flip on a 1-wide processor since all register writes happen at the WB stage and instructions never overtake each other. But in a 2-wide processor, when a LOAD instruction and an ALU instruction both attempt to write to the same register at the WB stage, there are no guarantees on who will write first. Hence stalls are inserted at the WB stage to enforce the correct ordering. If there is a hazard, the older instruction is allowed to write first to the register file while the younger instruction stalls for one cycle.</li>
<li>WAR (Write After Read) hazards: This is when an instruction writes to a register read by a previous instruction. If their orders are flipped, then this too can produce wrong outcomes, just like RAW or WAW hazards. However, for a WAR hazard, our in-order processor design guarantees the correct ordering because writes happen at the WB stage and reads happen at the ID stage. There is no situation where the WB stage of a younger instruction overtakes the ID stage of an older instruction. So we do not need to worry about this particular hazard. As an aside, if our processor had an out-of-order design where instructions are dynamically scheduled to execute out of order, WAR hazards would have been a cause for concern.</li>
<li>RAR (Read After Read) hazards? No such thing exists. Two reads to a register can happen in any order without changing the outcome. :)</li>
</ul>
<h3>Control hazards</h3>
<p>A control hazard occurs because on a conditional branch instruction, there is a delay between the fetch of the instruction and when the condition is resolved in the EX stage. Meanwhile the processor keeps on fetching subsequent instructions using PC + 4. At the very next instruction the branch instruction is at the ID stage so the processor doesn't even yet know this is a branch. At the next, next instruction, the branch is at the EX stage so the processor knows that it is a branch instruction by now but still doesn't know the direction the branch will go. Now if the branch turns out to be a not taken branch then there is no control hazard. The instructions you fetched meanwhile turned out to be the correct instructions! But if the branch turns out to be taken, the processor needs to flush the pipeline of those "meanwhile" instructions and start from the correct path.</p>
<p>In terms of your simulator, this means on a taken branch, inserting bubbles into the pipeline until the branch EX stage is over. How do you know if it is a taken branch? Fortunately, the generated trace entry already contains the Addr item which is the target address that the branch jumped (or did not jump) to. So if it is a taken branch, emulate the pipeline flush by inserting bubbles at the IF stage.</p>
<h2>Task 2: Enabling Optimizations on the Hazards</h2>
<p>Implement all the hazard avoidance optimizations that were described in the <a href="#configuration-files">Configuration Files</a> section and enable them when they are turned on in the configuration file. Be careful that while the optimizations will reduce hazards drastically, there are some hazards that remain even after the optimizations. After having completed this step, your five_stage simulator should be identical to the fve_stage_solution simulator and all diff tests should pass.</p>
<h2>Task 3: Analyzing Performance Plots</h2>
<p>First, generate the IPC.pdf and IPC_solution.pdf performance plots and verify that they are identical. Refer to the <a href="#creating-performance-plots">Creating Performance Plots</a> section on how to generate these plots. Then, answer the Project 1 Retrospective questions by analyzing the plots. <b>If your plot differs from the solution plot due to incomplete implementation, please use the solution plot to answer the questions</b>.</p>
<h2>Source Code</h2>
<p>Each trace file is a sequence of dynamic trace items, where each trace item represents one instruction executed in the program that has been traced. After five_stage.c reads a trace item, it stores it in a structure:</p>
<p>``` struct instruction { uint8_t type; // holds the op-code - see below uint8_t sReg_a; // 1st operand uint8_t sReg_b; // 2nd operand uint8_t dReg; // dest. operand uint32_t PC; // program counter uint32_t Addr; // mem. address }; ``` where: ``` enum opcode_type { ti_NOP = 0, ti_RTYPE, ti_ITYPE, ti_LOAD, ti_STORE, ti_BRANCH, ti_JTYPE, ti_SPECIAL, ti_JRTYPE }; ```</p>
<p>The “PC” (program counter) field is the address of the instruction itself. The “type” of an instruction provides the key information about the instruction. A detailed list of instructions is given below:</p>
<p>``` NOP - it's a no-op. No further information is provided. RTYPE - An R-type instruction. sReg_a: first register operand (register name) sReg_b: second register operand (register name) dReg: destination register name PC: program counter of this instruction Addr: not used ITYPE - An I-type instruction that is not LOAD, STORE, or BRANCH. sReg_a: first register operand (register name) sReg_b: not used dReg: destination register name PC: program counter of this instruction Addr: immediate value LOAD - a load instruction (memory access) sReg_a: first register operand (register name) sReg_b: not used dReg: destination register name PC: program counter of this instruction Addr: memory address STORE - a store instruction (memory access) sReg_a: first register operand (register name) sReg_b: second register operand (register name) dReg: not used PC: program counter of this instruction Addr: memory address BRANCH - a branch instruction sReg_a: first register operand (register name) sReg_b: second register operand (register name) dReg: not used PC: program counter of this instruction Addr: target address (the actual address of the next executed instruction) JTYPE - a jump instruction sReg_a: not used sReg_b: not used dReg: not used PC: program counter of this instruction Addr: target address (the actual address of the next executed instruction) SPECIAL - it's a special system call instruction For now, ignore other fields of this instruction. JRTYPE - a jump register instruction (used for "return" in functions) sReg_a: source register (that keeps the target address) sReg_b: not used dReg: not used PC: program counter of this instruction Addr: target address (the actual address of the next executed instruction) ```</p>
<h2>Submission</h2>
<p>Each pairwise group will submit the exercise <em>once</em> to GradeScope, by <em>one member</em> of the group. The submitting member will press the "View or edit group" link at the top-right corner of the assignment page after submission to add his/her partner. That way, both of you will get a grade. This applies to both the Project 1 Source Code and Project 1 Retrospective submissions explained below.</p>
<p>You will do two submissions for this deliverable.</p>
<ol type="1">
<li><p class="startli">**(90 points)** Project 1 Soure Code (Due Oct.13 5:00 PM)</p>
<p class="startli">The recommened way to submit the source code is by submitting your GitHub repository. Create a <b>PRIVATE</b> github repository just for Project 1 (with only the files within this folder in it). Add your partner as a collaborator so both of you have access. Make sure you keep the repository <b>PRIVATE</b> so that nobody else can access your repository. The reason I recommend this method is because GitHub is a good way to version your code so that your project doesn't evaporate if you spill coffee on your laptop. Also, GitHub allows easy collaboration between your partner by having a central repository. Those of you who are new to Git, here are some slides I have cooked up (which I don't have time to go over in class, but they are pretty much self explanatory):</p>
<p class="startli"><a href="https://github.com/wonsunahn/CS1541_Fall2020/blob/master/lectures/Using_Git.pdf">https://github.com/wonsunahn/CS1541_Fall2020/blob/master/lectures/Using_Git.pdf</a></p>
<p class="startli">Once you are done modifying code, don't forget to commit and push your changes to the github repository. Before you commit your changes, please do 'make distclean' so that you don't commit your large debug output files with your source code. When you are done, submit your GitHub repository to GradeScope at the "Project 1 Soure Code" link. Once you submit, GradeScope will run the autograder to grade you and give you instant feedback. If you get deductions, fix your code based on the feedback and resubmit. Repeat until you don't get deductions. You will get deductions based on the number of failed diffs (-5 per failed diff). This part of the submission is worth 90 points. You start out with 18 failed diffs (out of 32) with no modifications to code, so you start out with 90 - 18 * 5 = 0 points.</p>
<p class="startli">The alternative way to submit your source code is to directly upload the files. All you have to do is drag and drop source files that you have modified on to the Upload window and press the Upload button. The default files in this folder will be used for any files that you don't upload. While this method in the short run is simpler than the GitHub method, you will find that using a source repository like GitHub is beneficial in the long run.</p>
<p class="startli"><b>WARNING: Leaving your GitHub public, like any other method of publicizing your code, will be considered abetting plagiarism.</b></p>
</li>
</ol>
<ol type="1">
<li><p class="startli">**(20 points)** Project 1 Retrospective (Due Oct.20 5:00 PM)</p>
<p class="startli">Click on the GradeScope "Project 1 Retrospective" link and answer the questions based on <a href="#task-3-analyzing-performance-plots">Task 3: Analyzing Performance Plots</a>. Note that this submission is worth 20, not 10, points. That is because 10 points are <b>extra credit</b>. 10 points worth of questions are either multiple choice or fill-in-the-blank questions which are easily answerable by simply reading the plot. 10 points worth of questions (the extra credit) are short answer questions that ask you to explain and make conjectures about the experimental results, and require some additional thinking.</p>
<p class="startli">Just like other scientists, computer architects try to draw conclusions from experimental data from their simulators. Some conclusions are strongly supported by the data and other conclusions less so. In a proper scientific publication, architects publish both the raw data and the conclusions they derived from it. It is up to the reader to judge the strength of each conclusion based on the data provided. By doing the extra credit, you will practice drawing conclusions from data, just like architects do every day. Since this is extra credit, I will expect you to write a reasonable conclusion &mdash; something that is not supported by the data and your knowledge of the simulator will not get you any points.</p>
</li>
</ol>
<h1>Resources</h1>
<ul>
<li>Windows SSH Terminal Client: <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">Putty</a></li>
<li>File Transfer Client: <a href="https://filezilla-project.org/download.php?type=client">FileZilla</a></li>
<li>Linux command line tutorial: <a href="http://linuxcommand.org/lc3_learning_the_shell.php">The Linux Command Line</a></li>
<li>GitHub tutorial: <a href="https://github.com/wonsunahn/CS1541_Fall2020/blob/master/lectures/Using_Git.pdf">Using Git</a></li>
<li>GitHub GUI Client: <a href="https://desktop.github.com/">GitHub Desktop</a> </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.5
</small></address>
</body>
</html>
